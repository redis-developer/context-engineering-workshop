{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Module 3: Progressive Agents Demo\n",
    "\n",
    "## Workshop: Context Engineering Matters\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this module, you will:\n",
    "\n",
    "1. **Observe** the evolution from basic to production-ready RAG agents\n",
    "2. **Compare** three progressive stages of agent development\n",
    "3. **Understand** the impact of context engineering on real systems\n",
    "4. **Identify** when to apply each pattern in your own projects\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll See\n",
    "\n",
    "This notebook demonstrates **three stages** of RAG agent development using the same course catalog:\n",
    "\n",
    "### Stage 1: Baseline RAG (Information Overload)\n",
    "- **Problem**: Returns ALL course details for every match\n",
    "- **Result**: ~6,000+ tokens, overwhelming context\n",
    "- **Learning**: \"More information â‰  better answers\"\n",
    "- **Search**: Semantic (vector) search only\n",
    "\n",
    "### Stage 2: Context-Engineered (Optimized)\n",
    "- **Improvement**: Applies context engineering techniques\n",
    "- **Result**: ~539 tokens (91% reduction)\n",
    "- **Learning**: Clean, transform, optimize context\n",
    "- **Search**: Semantic (vector) search only\n",
    "\n",
    "### Stage 3: Hierarchical Retrieval (Production-Ready)\n",
    "- **Improvement**: Progressive disclosure + intent classification\n",
    "- **Result**: ~700 tokens with full syllabi for top matches\n",
    "- **Learning**: Best of both worlds - efficient AND informative\n",
    "- **Search**: Semantic (vector) search only\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” Note on Search Strategies\n",
    "\n",
    "**These stages (1-3) use semantic search only** because they focus on demonstrating **context engineering** techniques:\n",
    "- Stage 1: Information overload problem\n",
    "- Stage 2: Context optimization solutions\n",
    "- Stage 3: Progressive disclosure pattern\n",
    "\n",
    "**For hybrid search (semantic + keyword)**, see:\n",
    "- **Module 2**: Learn all search types (vector, keyword, hybrid)\n",
    "- **Stage 4+ Agents**: Production agents with hybrid search + NER\n",
    "- **Module 5**: Building agents with advanced search strategies\n",
    "\n",
    "This progression is intentional - master context engineering first, then add search complexity!\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Module 2: RAG Essentials\n",
    "- Redis Stack running with course data loaded\n",
    "- OpenAI API key configured\n",
    "\n",
    "---\n",
    "\n",
    "## Important Note\n",
    "\n",
    "These agents are **pre-built** in the `/progressive_agents` directory.\n",
    "\n",
    "**For this demo**, we'll run them from the command line and examine their outputs. The agents use async event loops that don't work well in Jupyter notebooks, so we'll use the CLI instead.\n",
    "\n",
    "In later modules, you'll learn how to build agents like these yourself.\n",
    "\n",
    "---"
   ],
   "id": "fb89e343bf08f62b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Part 1: Setup and Verification",
   "id": "6ff080079dd7abfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Verify we're in the right directory\n",
    "project_root = Path.cwd().parent if Path.cwd().name == \"workshop\" else Path.cwd()\n",
    "\n",
    "# Verify agents exist\n",
    "stage1_path = project_root / \"progressive_agents\" / \"stage1_baseline_rag\"\n",
    "stage2_path = project_root / \"progressive_agents\" / \"stage2_context_engineered\"\n",
    "stage3_path = project_root / \"progressive_agents\" / \"stage3_full_agent_without_memory\"\n",
    "\n",
    "print(f\"\"\"Setup Verification\n",
    "{'=' * 60}\n",
    "Project Root: {project_root}\n",
    "Stage 1 Agent: {'âœ“ Found' if stage1_path.exists() else 'âœ— Missing'}\n",
    "Stage 2 Agent: {'âœ“ Found' if stage2_path.exists() else 'âœ— Missing'}\n",
    "Stage 3 Agent: {'âœ“ Found' if stage3_path.exists() else 'âœ— Missing'}\n",
    "\"\"\")"
   ],
   "id": "2fb2d8da95cc5e1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Part 2: Stage 1 - Baseline RAG (Information Overload)\n",
    "\n",
    "### What This Stage Demonstrates\n",
    "\n",
    "**Architecture:**\n",
    "- Simple semantic search with Redis\n",
    "- Returns FULL course details for ALL matches\n",
    "- No context engineering or optimization\n",
    "\n",
    "**The Problem:**\n",
    "- Query: \"What machine learning courses are available?\"\n",
    "- Returns: Complete details for 5 courses (~6,000 tokens)\n",
    "- Includes: Full 14-week syllabi, all assignments, all prerequisites\n",
    "- Result: Information overload, high cost, degraded quality\n",
    "\n",
    "Let's run it from the command line:"
   ],
   "id": "b8cc14ba8b4558d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the query we'll use for all stages\n",
    "query = \"What machine learning courses are available for beginners?\"\n",
    "\n",
    "print(f\"\"\"Running Stage 1: Baseline RAG\n",
    "{'=' * 60}\n",
    "Query: \"{query}\"\n",
    "\n",
    "Command:\n",
    "  uv run python -m progressive_agents.stage1_baseline_rag.cli \"{query}\" --quiet\n",
    "\n",
    "Running...\n",
    "\"\"\")\n",
    "\n",
    "# Run Stage 1 agent\n",
    "result = subprocess.run(\n",
    "    [\"uv\", \"run\", \"python\", \"-m\", \"progressive_agents.stage1_baseline_rag.cli\", query, \"--quiet\"],\n",
    "    cwd=project_root,\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(f\"Error: {result.stderr}\")\n",
    "\n"
   ],
   "id": "bec9f96e71802d2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Stage 1 Analysis\n",
    "\n",
    "**Observations:**\n",
    "- âš ï¸ Returns full details for ALL matching courses\n",
    "- âš ï¸ Includes complete 14-week syllabi for every course\n",
    "- âš ï¸ High token usage (~6,000+ tokens)\n",
    "- âš ï¸ Information overload makes it hard to compare courses\n",
    "\n",
    "**Key Learning:**\n",
    "> \"More information â‰  better answers. Context engineering is about providing the RIGHT information, not ALL information.\"\n",
    "\n",
    "---"
   ],
   "id": "d869bc60d55f75d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 3: Stage 2 - Context-Engineered (Optimized)\n",
    "\n",
    "### What This Stage Demonstrates\n",
    "\n",
    "**Architecture:**\n",
    "- Same semantic search as Stage 1\n",
    "- **NEW**: Context engineering techniques applied\n",
    "- Cleans, transforms, and optimizes retrieved data\n",
    "\n",
    "**Context Engineering Techniques:**\n",
    "1. **Cleaning**: Remove noise fields (IDs, timestamps, enrollment data)\n",
    "2. **Transformation**: Convert JSON â†’ natural text format\n",
    "3. **Optimization**: Efficient token usage while preserving information\n",
    "\n",
    "**Expected Result:**\n",
    "- 91% token reduction (~539 tokens vs ~6,133)\n",
    "- Better LLM understanding (natural text vs JSON)\n",
    "- Trade-off: Lost syllabi to fit budget\n",
    "\n",
    "Let's run Stage 2:"
   ],
   "id": "46c3e8c9d5c2d309"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"\"\"Running Stage 2: Context-Engineered\n",
    "{'=' * 60}\n",
    "Query: \"{query}\"\n",
    "\n",
    "Command:\n",
    "  uv run python -m progressive_agents.stage2_context_engineered.cli \"{query}\" --quiet\n",
    "\n",
    "Running...\n",
    "\"\"\")\n",
    "\n",
    "# Run Stage 2 agent\n",
    "result2 = subprocess.run(\n",
    "    [\"uv\", \"run\", \"python\", \"-m\", \"progressive_agents.stage2_context_engineered.cli\", query, \"--quiet\"],\n",
    "    cwd=project_root,\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result2.stdout)\n",
    "\n",
    "if result2.returncode != 0:\n",
    "    print(f\"Error: {result2.stderr}\")"
   ],
   "id": "5e93a3256708bbf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Stage 2 Analysis\n",
    "\n",
    "**Improvements over Stage 1:**\n",
    "- âœ… 91% token reduction (from ~6,133 to ~539 tokens)\n",
    "- âœ… Natural text format (easier for LLM to parse)\n",
    "- âœ… Removed noise fields (cleaner context)\n",
    "- âœ… Same functionality, better efficiency\n",
    "\n",
    "**Trade-offs:**\n",
    "- âš ï¸ Lost detailed syllabi to fit token budget\n",
    "- âš ï¸ Less comprehensive information per course\n",
    "\n",
    "**Key Learning:**\n",
    "> \"Context engineering can dramatically reduce tokens while maintaining quality. But there's still room for improvement.\"\n",
    "\n",
    "---"
   ],
   "id": "3f58fbc19607069b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 4: Stage 3 - Hierarchical Retrieval (Production-Ready)\n",
    "\n",
    "### What This Stage Demonstrates\n",
    "\n",
    "**Architecture:**\n",
    "- **NEW**: Two-tier hierarchical retrieval\n",
    "- **NEW**: Progressive disclosure (summaries â†’ details on-demand)\n",
    "- **NEW**: Intent classification (greeting, overview, details)\n",
    "- Context engineering from Stage 2\n",
    "\n",
    "**How It Works:**\n",
    "1. Classify query intent (overview vs. detailed)\n",
    "2. Search summaries (lightweight, ~60 tokens each)\n",
    "3. Fetch details for top matches only (~500 tokens each)\n",
    "4. Adaptive retrieval based on query type\n",
    "\n",
    "**Expected Result:**\n",
    "- ~700 tokens with syllabi for top 2-3 matches\n",
    "- Best of both worlds: efficient + informative\n",
    "- Production-ready architecture\n",
    "\n",
    "Let's run Stage 3:"
   ],
   "id": "3dd5449272a72d19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"\"\"Running Stage 3: Hierarchical Retrieval\n",
    "{'=' * 60}\n",
    "Query: \"{query}\"\n",
    "\n",
    "Command:\n",
    "  uv run python -m progressive_agents.stage3_full_agent_without_memory.cli \"{query}\" --quiet\n",
    "\n",
    "Running...\n",
    "\"\"\")\n",
    "\n",
    "# Run Stage 3 agent\n",
    "result3 = subprocess.run(\n",
    "    [\"uv\", \"run\", \"python\", \"-m\", \"progressive_agents.stage3_full_agent_without_memory.cli\", query, \"--quiet\"],\n",
    "    cwd=project_root,\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result3.stdout)\n",
    "\n",
    "if result3.returncode != 0:\n",
    "    print(f\"Error: {result3.stderr}\")\n"
   ],
   "id": "b6b5494afdab81b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Stage 3 Analysis\n",
    "\n",
    "**Improvements over Stage 2:**\n",
    "- âœ… Includes syllabi for top matches (~700 tokens)\n",
    "- âœ… Progressive disclosure (summaries â†’ details)\n",
    "- âœ… Intent classification (adapts to query type)\n",
    "- âœ… Production-ready architecture\n",
    "\n",
    "**Best of Both Worlds:**\n",
    "- Efficient like Stage 2 (low token usage)\n",
    "- Informative like Stage 1 (includes syllabi)\n",
    "- Adaptive (changes behavior based on query)\n",
    "\n",
    "**Key Learning:**\n",
    "> \"Hierarchical retrieval with progressive disclosure is the production-ready pattern. It balances efficiency with information depth.\"\n",
    "\n",
    "---"
   ],
   "id": "d3b7c04196d21906"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 5: Side-by-Side Comparison\n",
    "\n",
    "Let's compare all three stages:"
   ],
   "id": "c8521ef5b9654c71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create comparison table (based on typical outputs)\n",
    "comparison_data = {\n",
    "    'Stage': ['Stage 1: Baseline', 'Stage 2: Context-Engineered', 'Stage 3: Hierarchical'],\n",
    "    'Architecture': [\n",
    "        'Flat retrieval',\n",
    "        'Flat + context engineering',\n",
    "        'Hierarchical + progressive disclosure'\n",
    "    ],\n",
    "    'Typical Tokens': [\n",
    "        '~6,133',\n",
    "        '~539',\n",
    "        '~700'\n",
    "    ],\n",
    "    'Includes Syllabi': ['âœ“ All courses', 'âœ— None', 'âœ“ Top matches'],\n",
    "    'Best For': [\n",
    "        'Prototyping',\n",
    "        'Token-constrained systems',\n",
    "        'Production systems'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(f\"\"\"Progressive Agents Comparison\n",
    "{'=' * 80}\n",
    "\"\"\")\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\n{'=' * 80}\")"
   ],
   "id": "2f05f4e3b53ce35a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visual Comparison: Token Usage\n",
    "\n",
    "```\n",
    "Stage 1: Baseline RAG\n",
    "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  ~6,133 tokens\n",
    "Problem: Information overload\n",
    "\n",
    "Stage 2: Context-Engineered\n",
    "â–ˆâ–ˆâ–ˆâ–ˆ  ~539 tokens (91% reduction)\n",
    "Problem: Lost syllabi\n",
    "\n",
    "Stage 3: Hierarchical Retrieval\n",
    "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  ~700 tokens (89% reduction, WITH syllabi)\n",
    "Solution: Best of both worlds âœ“\n",
    "```\n",
    "\n",
    "---"
   ],
   "id": "9818415eb7ac673"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part 6: Key Takeaways\n",
    "\n",
    "### The Evolution of RAG Systems\n",
    "\n",
    "1. **Stage 1 â†’ Stage 2**: Context engineering reduces tokens by 91%\n",
    "   - Cleaning, transformation, optimization\n",
    "   - Trade-off: Lost detailed information\n",
    "\n",
    "2. **Stage 2 â†’ Stage 3**: Hierarchical retrieval adds back details efficiently\n",
    "   - Progressive disclosure (summaries â†’ details)\n",
    "   - Intent classification (adaptive behavior)\n",
    "   - Production-ready architecture\n",
    "\n",
    "### When to Use Each Pattern\n",
    "\n",
    "| Pattern | Use When | Avoid When |\n",
    "|---------|----------|------------|\n",
    "| **Stage 1: Baseline** | Prototyping, small datasets | Production, large datasets |\n",
    "| **Stage 2: Context-Engineered** | Strict token budgets, simple queries | Need detailed information |\n",
    "| **Stage 3: Hierarchical** | Production systems, complex queries | Simple prototypes |\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "âœ… **Observed** the evolution from basic to production-ready RAG\n",
    "âœ… **Compared** three progressive stages with the same query\n",
    "âœ… **Understood** the impact of context engineering on real systems\n",
    "âœ… **Identified** when to apply each pattern in your projects\n",
    "\n",
    "---"
   ],
   "id": "cdb37f3d3bf892a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Next Steps\n",
    "\n",
    "### Module 4: Building Your Own Agent (Coming Soon)\n",
    "\n",
    "Now that you've seen these patterns in action, you'll learn how to build them yourself:\n",
    "\n",
    "1. **LangGraph Basics**: State machines, nodes, edges\n",
    "2. **Intent Classification**: Detecting query types\n",
    "3. **Progressive Disclosure**: Implementing two-tier retrieval\n",
    "4. **Memory Systems**: Adding conversation history (Stage 4)\n",
    "\n",
    "### Explore the Code\n",
    "\n",
    "Want to see how these agents work under the hood?\n",
    "\n",
    "```bash\n",
    "# Stage 1: Baseline RAG\n",
    "progressive_agents/stage1_baseline_rag/\n",
    "â”œâ”€â”€ agent/\n",
    "â”‚   â”œâ”€â”€ __init__.py          # Agent setup\n",
    "â”‚   â”œâ”€â”€ workflow.py          # LangGraph workflow\n",
    "â”‚   â””â”€â”€ nodes.py             # Workflow nodes\n",
    "â””â”€â”€ cli.py                   # Command-line interface\n",
    "\n",
    "# Stage 2: Context-Engineered\n",
    "progressive_agents/stage2_context_engineered/\n",
    "â”œâ”€â”€ agent/\n",
    "â”‚   â”œâ”€â”€ context_engineering.py  # NEW: Context optimization\n",
    "â”‚   â””â”€â”€ ...\n",
    "â””â”€â”€ cli.py\n",
    "\n",
    "# Stage 3: Hierarchical Retrieval\n",
    "progressive_agents/stage3_full_agent_without_memory/\n",
    "â”œâ”€â”€ agent/\n",
    "â”‚   â”œâ”€â”€ intent_classifier.py    # NEW: Intent detection\n",
    "â”‚   â”œâ”€â”€ research_planner.py     # NEW: Query planning\n",
    "â”‚   â””â”€â”€ ...\n",
    "â””â”€â”€ cli.py\n",
    "```\n",
    "\n",
    "### Try It Yourself\n",
    "\n",
    "Run the agents from the command line:\n",
    "\n",
    "```bash\n",
    "# Stage 1\n",
    "uv run python -m progressive_agents.stage1_baseline_rag.cli\n",
    "\n",
    "# Stage 2\n",
    "uv run python -m progressive_agents.stage2_context_engineered.cli\n",
    "\n",
    "# Stage 3\n",
    "uv run python -m progressive_agents.stage3_full_agent_without_memory.cli\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ What's Next: Advanced Search Strategies\n",
    "\n",
    "The stages you've seen (1-3) use **semantic search only** to focus on context engineering fundamentals.\n",
    "\n",
    "**Ready for production-grade search?** The advanced stages add:\n",
    "\n",
    "### Stage 4: Hybrid Search + Named Entity Recognition\n",
    "- **Combines**: Semantic search + exact matching + metadata filters\n",
    "- **Features**:\n",
    "  - Detects course codes in queries (\"Tell me about CS101\")\n",
    "  - Uses Tag filters for exact matches\n",
    "  - Falls back to semantic search for general queries\n",
    "- **Location**: `progressive_agents/stage4_hybrid_search/`\n",
    "\n",
    "### Stage 5+: Working Memory + Long-term Memory\n",
    "- **Adds**: Agent Memory Server integration\n",
    "- **Features**:\n",
    "  - Remembers user preferences (semantic search)\n",
    "  - Tracks conversation history\n",
    "  - Combines memory + course search\n",
    "- **Location**: `progressive_agents/stage5_working_memory/`\n",
    "\n",
    "### Why This Progression?\n",
    "\n",
    "```\n",
    "Module 2: Learn search types (vector, keyword, hybrid)\n",
    "    â†“\n",
    "Module 3: Master context engineering (semantic only)\n",
    "    â†“\n",
    "Module 4: Add memory systems (semantic for memories)\n",
    "    â†“\n",
    "Module 5: Production agents (hybrid search + memory)\n",
    "```\n",
    "\n",
    "**Each layer builds on the previous one!**\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations! ðŸŽ‰\n",
    "\n",
    "You've completed Module 3: Progressive Agents Demo. You've seen how context engineering evolves from basic retrieval to production-ready systems.\n",
    "\n",
    "**Key Insights:**\n",
    "> \"Context engineering is not a one-time optimization. It's an iterative process of understanding trade-offs and choosing the right architecture for your use case.\"\n",
    "\n",
    "> \"Different components need different search strategies. Semantic search for context engineering, hybrid search for production catalogs, no search for reference data.\"\n"
   ],
   "id": "9ba2afb2c8b2775e"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
